"""
Chatbot t∆∞ v·∫•n tuy·ªÉn sinh cho tr∆∞·ªùng Sentia School, t√≠ch h·ª£p ƒëa n·ªÅn t·∫£ng:
- Web interface (Flask)
- Telegram bot
- Facebook Messenger bot

Chatbot s·ª≠ d·ª•ng:
- OpenAI embeddings cho vector search
- Milvus l√†m vector database ƒë·ªÉ l∆∞u tr·ªØ c√°c ƒëo·∫°n vƒÉn b·∫£n
- GPT-4o-mini ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan
"""
import os
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from pymilvus import connections, Collection, utility
import numpy as np
from typing import List, Dict, Optional, Any, Union, cast
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from telegram_bot import TelegramBot
import threading
import json
# Import Facebook Messenger bot integration
from messanger_facebook import setup_facebook_messenger

# Load environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv('OPEN_API_KEY')
client = OpenAI(api_key=OPENAI_API_KEY)

# Milvus connection parameters
MILVUS_HOST = 'localhost'
MILVUS_PORT = '19530'
COLLECTION_NAME = "sentia_website"

# Initialize Flask app
app = Flask(__name__, static_folder='frontend')
CORS(app)

# Conversation history management
class ConversationManager:
    """
    L·ªõp qu·∫£n l√Ω l·ªãch s·ª≠ h·ªôi tho·∫°i, l∆∞u tr·ªØ c√°c tin nh·∫Øn gi·ªØa ng∆∞·ªùi d√πng v√† chatbot
    Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng tin nh·∫Øn ƒë·ªÉ tr√°nh qu√° t·∫£i context window c·ªßa OpenAI
    """
    def __init__(self, max_history: int = 5):
        self.history: List[Dict[str, str]] = []
        self.max_history = max_history
    
    def add_message(self, role: str, content: str):
        """Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        if content is None:
            content = ""  # ƒê·∫£m b·∫£o content kh√¥ng bao gi·ªù l√† None
        self.history.append({"role": role, "content": content})
        if len(self.history) > self.max_history * 2:
            self.history = self.history[-self.max_history * 2:]
    
    def get_history(self) -> List[Dict[str, str]]:
        """L·∫•y to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        return self.history
    
    def clear(self):
        """X√≥a to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        self.history = []

# Initialize conversation manager
conversation_manager = ConversationManager()

# Telegram Bot configuration
TELEGRAM_TOKEN = "7617019912:AAH1Ws5xaO54Gpktg3qdIHH4RLiHNsZyRvc"

def get_embedding(text):
    """
    L·∫•y vector embedding t·ª´ OpenAI API cho vƒÉn b·∫£n ƒë·∫ßu v√†o
    S·ª≠ d·ª•ng model text-embedding-3-large ƒë·ªÉ c√≥ ƒë·ªô ch√≠nh x√°c cao
    """
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-large"
    )
    return response.data[0].embedding

def search_similar_chunks(query, top_k=5):
    """
    T√¨m ki·∫øm c√°c ƒëo·∫°n vƒÉn b·∫£n t∆∞∆°ng t·ª± trong c∆° s·ªü d·ªØ li·ªáu Milvus
    S·ª≠ d·ª•ng vector embedding ƒë·ªÉ t√¨m ki·∫øm ng·ªØ nghƒ©a, kh√¥ng ph·∫£i t·ª´ kh√≥a
    
    Args:
        query: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
        
    Returns:
        List[Dict]: Danh s√°ch c√°c ƒëo·∫°n vƒÉn b·∫£n t∆∞∆°ng t·ª± k√®m th√¥ng tin
    """
    similar_chunks = []
    
    try:
        # Connect to Milvus
        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)
        
        # Get collection
        collection = Collection(COLLECTION_NAME)
        collection.load()
        
        # Get query embedding
        query_embedding = get_embedding(query)
        
        # Search parameters
        search_params = {
            "metric_type": "L2",
            "params": {"nprobe": 10}
        }
        
        # Th·ª±c hi·ªán t√¨m ki·∫øm
        future = collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            output_fields=["content", "page_title", "url", "page_number", "chunk_index", "is_chunked"]
        )
        
        # C·∫•u tr√∫c k·∫øt qu·∫£ t·ª´ pymilvus th∆∞·ªùng g·ªìm danh s√°ch c√°c hits cho m·ªói vector query
        if hasattr(future, '__getitem__'):
            result_list = future[0]  # L·∫•y k·∫øt qu·∫£ cho vector ƒë·∫ßu ti√™n
            for hit in result_list:
                # T·∫°o source info t·ª´ page info
                entity = hit.entity
                page_title = getattr(entity, 'page_title', 'Unknown')
                url = getattr(entity, 'url', '')
                page_num = getattr(entity, 'page_number', '')
                chunk_idx = getattr(entity, 'chunk_index', 0)
                is_chunked = getattr(entity, 'is_chunked', False)
                content = getattr(entity, 'content', '')
                
                # T·∫°o source string
                source = f"{page_title}"
                if page_num:
                    source += f" (Trang {page_num})"
                if is_chunked and chunk_idx > 0:
                    source += f" - Ph·∫ßn {chunk_idx + 1}"
                
                similar_chunks.append({
                    "text": content,
                    "source": source,
                    "url": url,
                    "distance": hit.distance,
                    "page_title": page_title,
                    "page_number": page_num,
                    "is_chunked": is_chunked
                })
        else:
            print("ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ kh√¥ng ƒë√∫ng nh∆∞ mong ƒë·ª£i")
            
    except Exception as e:
        print(f"L·ªói trong search_similar_chunks: {e}")
    
    return similar_chunks

def generate_response(query: str, context_chunks: List[Dict]) -> str:
    """
    T·∫°o c√¢u tr·∫£ l·ªùi s·ª≠ d·ª•ng GPT-4o-mini v·ªõi context v√† l·ªãch s·ª≠ h·ªôi tho·∫°i
    
    Args:
        query: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        context_chunks: Danh s√°ch c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan t·ª´ c∆° s·ªü d·ªØ li·ªáu
        
    Returns:
        str: C√¢u tr·∫£ l·ªùi t·ª´ AI
    """
    # Prepare context
    context = "\n\n".join([f"Source: {chunk['source']}\nContent: {chunk['text']}" for chunk in context_chunks])
    
    # Create system message
    system_message = """B·∫°n l√† AI Assistant t∆∞ v·∫•n tuy·ªÉn sinh chuy√™n nghi·ªáp c·ªßa tr∆∞·ªùng Sentia School.

NHI·ªÜM V·ª§ CH√çNH:
- Tr·∫£ l·ªùi chi ti·∫øt, ch√≠nh x√°c v·ªÅ m·ªçi th√¥ng tin li√™n quan ƒë·∫øn Sentia School
- S·ª≠ d·ª•ng gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp v√† thuy·∫øt ph·ª•c
- C√°c c√¢u h·ªèi ch√†o, hello,... b·∫°n ph·∫£i tr·∫£ l·ªùi t·ª´ t·ªën h·ªèi xem ng∆∞·ªùi d√πng c√≥ c·∫ßn gi√∫p ƒë·ª° g√¨ kh√¥ng 
- Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn tr∆∞·ªùng, gi√°o d·ª•c
- N·∫øu c√¢u h·ªèi ngo√†i ph·∫°m vi ki·∫øn th·ª©c th√¨ tr·∫£ l·ªùi, ngo√†i tr·ª´ Hello, xin ch√†o,....: "Xin l·ªói, t√¥i ch·ªâ c√≥ th·ªÉ t∆∞ v·∫•n v·ªÅ Sentia School"

C√ÅCH TR√åNH B√ÄY:
‚ú® S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ t·∫°o ƒëi·ªÉm nh·∫•n
üìã Chia th√†nh c√°c m·ª•c r√µ r√†ng v·ªõi emoji ƒë·∫ßu d√≤ng
üìû Lu√¥n cung c·∫•p th√¥ng tin li√™n h·ªá khi c√≥ th·ªÉ
üéØ Khuy·∫øn kh√≠ch h√†nh ƒë·ªông c·ª• th·ªÉ

FORMAT RESPONSE:
- D√πng √≠t ** (ch·ªâ cho ti√™u ƒë·ªÅ quan tr·ªçng)
- S·ª≠ d·ª•ng emoji thay v√¨ ** cho ƒëi·ªÉm nh·∫•n
- Xu·ªëng d√≤ng r√µ r√†ng gi·ªØa c√°c √Ω
- D√πng ‚Ä¢ ho·∫∑c ‚úì cho danh s√°ch thay v√¨ -

V√ç D·ª§ FORMAT T·ªêT:
üè´ **V·ªÅ Sentia School**
‚ú® Tr∆∞·ªùng ƒë∆∞·ª£c th√†nh l·∫≠p nƒÉm...
üìö Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o bao g·ªìm:
‚Ä¢ M√¥n A
‚Ä¢ M√¥n B
üìû Li√™n h·ªá: 024 3789 4666, 0906 288 849, 0896 675 889 """
    
    # Chu·∫©n b·ªã tin nh·∫Øn theo ƒë·ªãnh d·∫°ng OpenAI c·∫ßn
    from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam, ChatCompletionAssistantMessageParam
    
    # T·∫°o messages v·ªõi ki·ªÉu d·ªØ li·ªáu c·ª• th·ªÉ
    system_messages = [
        ChatCompletionSystemMessageParam(role="system", content=system_message),
        ChatCompletionSystemMessageParam(role="system", content=f"Context from documents:\n{context}")
    ]
    
    # Chuy·ªÉn ƒë·ªïi conversation history
    history_messages = []
    for msg in conversation_manager.get_history():
        if msg["role"] == "user":
            history_messages.append(ChatCompletionUserMessageParam(role="user", content=msg["content"]))
        elif msg["role"] == "assistant":
            history_messages.append(ChatCompletionAssistantMessageParam(role="assistant", content=msg["content"]))
        elif msg["role"] == "system":
            history_messages.append(ChatCompletionSystemMessageParam(role="system", content=msg["content"]))
    
    # Th√™m c√¢u h·ªèi hi·ªán t·∫°i
    current_message = ChatCompletionUserMessageParam(role="user", content=query)
    
    # K·∫øt h·ª£p t·∫•t c·∫£ messages
    all_messages = system_messages + history_messages + [current_message]
    
    try:
        # Generate response
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=all_messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        # ƒê·∫£m b·∫£o response c√≥ n·ªôi dung
        if response and response.choices and len(response.choices) > 0:
            return response.choices[0].message.content or ""
        return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi l√∫c n√†y."
    except Exception as e:
        print(f"L·ªói khi t·∫°o response: {e}")
        return "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n."

# Initialize Telegram Bot
telegram_bot = TelegramBot(TELEGRAM_TOKEN, search_similar_chunks, generate_response)

@app.route('/')
def serve_frontend():
    """Ph·ª•c v·ª• trang ch·ªß c·ªßa ·ª©ng d·ª•ng web"""
    return send_from_directory('frontend', 'index.html')

@app.route('/<path:path>')
def serve_static(path):
    """Ph·ª•c v·ª• c√°c file tƒ©nh (CSS, JS, images,...)"""
    return send_from_directory('frontend', path)

@app.route('/chat', methods=['POST'])
def chat():
    """
    API endpoint x·ª≠ l√Ω tin nh·∫Øn t·ª´ giao di·ªán web
    Nh·∫≠n c√¢u h·ªèi, t√¨m ki·∫øm n·ªôi dung li√™n quan, t·∫°o c√¢u tr·∫£ l·ªùi v√† tr·∫£ v·ªÅ k·∫øt qu·∫£
    """
    data = request.get_json()
    query = data.get('message', '')
    
    if not query:
        return jsonify({'error': 'No message provided'}), 400
    
    try:
        # Add user query to history
        conversation_manager.add_message("user", query)
        
        # Search for relevant chunks
        similar_chunks = search_similar_chunks(query)
        
        if not similar_chunks:
            return jsonify({
                'response': 'Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü d·ªØ li·ªáu.',
                'sources': []
            })
        
        # Generate response
        response = generate_response(query, similar_chunks)
        
        # Add assistant response to history
        conversation_manager.add_message("assistant", response)
        
        # Get sources with URLs
        sources = []
        for chunk in similar_chunks:
            source_info = {
                'title': chunk['source'],
                'url': chunk.get('url', ''),
                'page_title': chunk.get('page_title', ''),
                'is_chunked': chunk.get('is_chunked', False)
            }
            if source_info not in sources:
                sources.append(source_info)
        
        return jsonify({
            'response': response,
            'sources': sources[:3],  # Ch·ªâ l·∫•y 3 source ch√≠nh
            'total_chunks': len(similar_chunks)
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500


# Initialize Facebook Messenger Bot
messenger_bot = None

def run_telegram_bot():
    """Ch·∫°y Telegram bot trong thread ri√™ng"""
    telegram_bot.run_polling()

def run_facebook_bot():
    """Set up Facebook Messenger integration trong thread ri√™ng"""
    global messenger_bot
    messenger_bot = setup_facebook_messenger(app, search_similar_chunks, generate_response)
    print("ü§ñ Facebook Messenger Bot ƒë√£ kh·ªüi ƒë·ªông!")

if __name__ == "__main__":
    # Ch·∫°y Telegram bot trong background thread
    telegram_thread = threading.Thread(target=run_telegram_bot, daemon=True)
    telegram_thread.start()
    
    # Ch·∫°y Facebook Messenger bot
    facebook_thread = threading.Thread(target=run_facebook_bot, daemon=True)
    facebook_thread.start()
    
    print("ü§ñ Telegram bot ƒë√£ kh·ªüi ƒë·ªông!")
    print(f"üì± Truy c·∫≠p bot t·∫°i: t.me/sentia2015_bot")
    print("ü§ñ Facebook Messenger ƒë√£ kh·ªüi ƒë·ªông!")
    print("üåê Flask server ƒëang ch·∫°y...")
    
    # Ch·∫°y Flask server
    app.run(debug=False, host='0.0.0.0', port=5000)
